{"type": "start", "purpose": "Kickoff context", "created_at": "2025-09-11T20:07:10.223473+00:00", "tool": "context-bundle-writer", "version": "1"}
{"type": "file", "path": "/Users/ciarancox/Archon/AGENTS.md", "relpath": "AGENTS.md", "size": 14103, "sha256": "45fc4851faad30edc091978a6920261ffe1a82b44ac8411f5fddf258f3d8e011", "created_at": "2025-09-11T20:07:53.995761+00:00", "content": "# AGENTS.md\n\n## Beta Development Guidelines\n\n**Local-only deployment** - each user runs their own instance.\n\n### Core Principles\n\n- **No backwards compatibility** - remove deprecated code immediately\n- **Detailed errors over graceful failures** - we want to identify and fix issues fast\n- **Break things to improve them** - beta is for rapid iteration\n\n### Error Handling\n\n**Core Principle**: In beta, we need to intelligently decide when to fail hard and fast to quickly address issues, and when to allow processes to complete in critical services despite failures. Read below carefully and make intelligent decisions on a case-by-case basis.\n\n#### When to Fail Fast and Loud (Let it Crash!)\n\nThese errors should stop execution and bubble up immediately: (except for crawling flows)\n\n- **Service startup failures** - If credentials, database, or any service can't initialize, the system should crash with a clear error\n- **Missing configuration** - Missing environment variables or invalid settings should stop the system\n- **Database connection failures** - Don't hide connection issues, expose them\n- **Authentication/authorization failures** - Security errors must be visible and halt the operation\n- **Data corruption or validation errors** - Never silently accept bad data, Pydantic should raise\n- **Critical dependencies unavailable** - If a required service is down, fail immediately\n- **Invalid data that would corrupt state** - Never store zero embeddings, null foreign keys, or malformed JSON\n\n#### When to Complete but Log Detailed Errors\n\nThese operations should continue but track and report failures clearly:\n\n- **Batch processing** - When crawling websites or processing documents, complete what you can and report detailed failures for each item\n- **Background tasks** - Embedding generation, async jobs should finish the queue but log failures\n- **WebSocket events** - Don't crash on a single event failure, log it and continue serving other clients\n- **Optional features** - If projects/tasks are disabled, log and skip rather than crash\n- **External API calls** - Retry with exponential backoff, then fail with a clear message about what service failed and why\n\n#### Critical Nuance: Never Accept Corrupted Data\n\nWhen a process should continue despite failures, it must **skip the failed item entirely** rather than storing corrupted data:\n\n**❌ WRONG - Silent Corruption:**\n\n```python\ntry:\n    embedding = create_embedding(text)\nexcept Exception as e:\n    embedding = [0.0] * 1536  # NEVER DO THIS - corrupts database\n    store_document(doc, embedding)\n```\n\n**✅ CORRECT - Skip Failed Items:**\n\n```python\ntry:\n    embedding = create_embedding(text)\n    store_document(doc, embedding)  # Only store on success\nexcept Exception as e:\n    failed_items.append({'doc': doc, 'error': str(e)})\n    logger.error(f\"Skipping document {doc.id}: {e}\")\n    # Continue with next document, don't store anything\n```\n\n**✅ CORRECT - Batch Processing with Failure Tracking:**\n\n```python\ndef process_batch(items):\n    results = {'succeeded': [], 'failed': []}\n\n    for item in items:\n        try:\n            result = process_item(item)\n            results['succeeded'].append(result)\n        except Exception as e:\n            results['failed'].append({\n                'item': item,\n                'error': str(e),\n                'traceback': traceback.format_exc()\n            })\n            logger.error(f\"Failed to process {item.id}: {e}\")\n\n    # Always return both successes and failures\n    return results\n```\n\n#### Error Message Guidelines\n\n- Include context about what was being attempted when the error occurred\n- Preserve full stack traces with `exc_info=True` in Python logging\n- Use specific exception types, not generic Exception catching\n- Include relevant IDs, URLs, or data that helps debug the issue\n- Never return None/null to indicate failure - raise an exception with details\n- For batch operations, always report both success count and detailed failure list\n\n### Code Quality\n\n- Remove dead code immediately rather than maintaining it - no backward compatibility or legacy functions\n- Prioritize functionality over production-ready patterns\n- Focus on user experience and feature completeness\n- When updating code, don't reference what is changing (avoid keywords like LEGACY, CHANGED, REMOVED), instead focus on comments that document just the functionality of the code\n\n## Architecture Overview\n\nArchon V2 Beta is a microservices-based knowledge management system with MCP (Model Context Protocol) integration:\n\n- **Frontend (port 3737)**: React + TypeScript + Vite + TailwindCSS\n  - **UI Strategy**: Radix UI primitives in `/features`, custom components in legacy `/components`\n  - **State Management**: TanStack Query for all data fetching in `/features`\n  - **Styling**: Tron-inspired glassmorphism with Tailwind CSS\n- **Main Server (port 8181)**: FastAPI with HTTP polling for updates\n- **MCP Server (port 8051)**: Lightweight HTTP-based MCP protocol server\n- **Agents Service (port 8052)**: PydanticAI agents for AI/ML operations\n- **Database**: Supabase (PostgreSQL + pgvector for embeddings)\n\n## Development Commands\n\n### Frontend (archon-ui-main/)\n\n```bash\nnpm run dev              # Start development server on port 3737\nnpm run build            # Build for production\nnpm run lint             # Run ESLint\nnpm run test             # Run Vitest tests\nnpm run test:coverage    # Run tests with coverage report\n```\n\n# Biome Linter Guide for AI Assistants\n\n## Overview\n\nThis project uses Biome for linting and formatting the `/src/features` directory. Biome provides fast, machine-readable feedback that AI assistants can use to improve code quality.\n\n## Configuration\n\nBiome is configured in `biome.json`:\n\n- **Scope**: Only checks `/src/features/**` directory\n- **Formatting**: 2 spaces, 80 char line width\n- **Linting**: Recommended rules enabled\n- **Import Organization**: Automatically sorts and groups imports\n\n## AI Assistant Workflow in the new /features directory\n\n1. **Check Issues**: Run `npm run biome:ai` to get JSON output\n2. **Parse Output**: Extract error locations and types\n3. **Apply Fixes**:\n   - Run `npm run biome:ai-fix` for auto-fixable issues\n   - Manually fix remaining issues based on patterns above\n4. **Verify**: Run `npm run biome:ai` again to confirm fixes\n\n## JSON Output Format\n\nWhen using `biome:ai`, the output is structured JSON:\n\n```json\n{\n  \"diagnostics\": [\n    {\n      \"file\": \"path/to/file.tsx\",\n      \"line\": 10,\n      \"column\": 5,\n      \"severity\": \"error\",\n      \"message\": \"Description of the issue\",\n      \"rule\": \"lint/a11y/useButtonType\"\n    }\n  ]\n}\n```\n\n### Backend (python/)\n\n```bash\n# Using uv package manager\nuv sync                  # Install/update dependencies\nuv run pytest            # Run tests\nuv run python -m src.server.main  # Run server locally\n\n# With Docker\ndocker-compose up --build -d       # Start all services\ndocker-compose logs -f             # View logs\ndocker-compose restart              # Restart services\n```\n\n### Testing\n\n```bash\n# Frontend tests (from archon-ui-main/)\nnpm run test:coverage:stream       # Run with streaming output\nnpm run test:ui                    # Run with Vitest UI\n\n# Backend tests (from python/)\nuv run pytest tests/test_api_essentials.py -v\nuv run pytest tests/test_service_integration.py -v\n```\n\n## Key API Endpoints\n\n### Knowledge Base\n\n- `POST /api/knowledge/crawl` - Crawl a website\n- `POST /api/knowledge/upload` - Upload documents (PDF, DOCX, MD)\n- `GET /api/knowledge/items` - List knowledge items\n- `POST /api/knowledge/search` - RAG search\n\n### MCP Integration\n\n- `GET /api/mcp/health` - MCP server status\n- `POST /api/mcp/tools/{tool_name}` - Execute MCP tool\n- `GET /api/mcp/tools` - List available tools\n\n### Projects & Tasks (when enabled)\n\n- `GET /api/projects` - List all projects\n- `POST /api/projects` - Create project\n- `GET /api/projects/{id}` - Get single project\n- `PUT /api/projects/{id}` - Update project\n- `DELETE /api/projects/{id}` - Delete project\n- `GET /api/projects/{id}/tasks` - Get tasks for project (use this, not getTasks)\n- `POST /api/tasks` - Create task\n- `PUT /api/tasks/{id}` - Update task\n- `DELETE /api/tasks/{id}` - Delete task\n\n## Polling Architecture\n\n### HTTP Polling (replaced Socket.IO)\n\n- **Polling intervals**: 1-2s for active operations, 5-10s for background data\n- **ETag caching**: Reduces bandwidth by ~70% via 304 Not Modified responses\n- **Smart pausing**: Stops polling when browser tab is inactive\n- **Progress endpoints**: `/api/progress/crawl`, `/api/progress/project-creation`\n\n### Key Polling Hooks\n\n- `usePolling` - Generic polling with ETag support\n- `useDatabaseMutation` - Optimistic updates with rollback\n- `useProjectMutation` - Project-specific operations\n\n## Environment Variables\n\nRequired in `.env`:\n\n```bash\nSUPABASE_URL=https://your-project.supabase.co\nSUPABASE_SERVICE_KEY=your-service-key-here\n```\n\nOptional:\n\n```bash\nOPENAI_API_KEY=your-openai-key        # Can be set via UI\nLOGFIRE_TOKEN=your-logfire-token      # For observability\nLOG_LEVEL=INFO                         # DEBUG, INFO, WARNING, ERROR\n```\n\n## File Organization\n\n### Frontend Structure\n\n- `src/components/` - Legacy UI components (custom-built)\n- `src/features/` - Modern vertical slice architecture with Radix UI\n  - `ui/primitives/` - Radix UI primitives with Tron glassmorphism\n  - `projects/` - Project management feature\n  - `tasks/` - Task management sub-feature\n- `src/pages/` - Main application pages\n- `src/services/` - API communication and business logic\n- `src/hooks/` - Custom React hooks\n- `src/contexts/` - React context providers\n\n### UI Libraries\n\n- **Radix UI** (@radix-ui/react-\\*) - Unstyled, accessible primitives for `/features`\n- **TanStack Query** - Data fetching and caching for `/features`\n- **React DnD** - Drag and drop for Kanban boards\n- **Tailwind CSS** - Utility-first styling with Tron-inspired glassmorphism\n- **Framer Motion** - Animations (minimal usage)\n\n### Theme Management\n\n- **ThemeContext** - Manages light/dark theme state\n- **Tailwind dark mode** - Uses `dark:` prefix with selector strategy\n- **Automatic switching** - All components respect theme via Tailwind classes\n- **Persistent** - Theme choice saved in localStorage\n- **Tron aesthetic** - Stronger neon glows in dark mode, subtle in light mode\n\nWe're migrating to a vertical slice architecture where each feature is self-contained. Features are organized by domain hierarchy - main features contain their sub-features. For example, tasks are a sub-feature of projects, so they live at `features/projects/tasks/` rather than as separate siblings. Each feature level has its own components, hooks, types, and services folders. This keeps related code together and makes the codebase more maintainable as it scales.\n\n### Backend Structure\n\n- `src/server/` - Main FastAPI application\n- `src/server/api_routes/` - API route handlers\n- `src/server/services/` - Business logic services\n- `src/mcp/` - MCP server implementation\n- `src/agents/` - PydanticAI agent implementations\n\n## Database Schema\n\nKey tables in Supabase:\n\n- `sources` - Crawled websites and uploaded documents\n- `documents` - Processed document chunks with embeddings\n- `projects` - Project management (optional feature)\n- `tasks` - Task tracking linked to projects\n- `code_examples` - Extracted code snippets\n\n## API Naming Conventions\n\n### Task Status Values\n\nUse database values directly (no UI mapping):\n\n- `todo`, `doing`, `review`, `done`\n\n### Service Method Patterns\n\n- `get[Resource]sByProject(projectId)` - Scoped queries\n- `get[Resource](id)` - Single resource\n- `create[Resource](data)` - Create operations\n- `update[Resource](id, updates)` - Updates\n- `delete[Resource](id)` - Soft deletes\n\n### State Naming\n\n- `is[Action]ing` - Loading states (e.g., `isSwitchingProject`)\n- `[resource]Error` - Error messages\n- `selected[Resource]` - Current selection\n\n## Common Development Tasks\n\n### Add a new API endpoint\n\n1. Create route handler in `python/src/server/api_routes/`\n2. Add service logic in `python/src/server/services/`\n3. Include router in `python/src/server/main.py`\n4. Update frontend service in `archon-ui-main/src/services/`\n\n### Add a new UI component\n\nFor **features** directory (preferred for new components):\n\n1. Use Radix UI primitives from `src/features/ui/primitives/`\n2. Create component in relevant feature folder under `src/features/`\n3. Use TanStack Query for data fetching\n4. Apply Tron-inspired glassmorphism styling with Tailwind\n\nFor **legacy** components:\n\n1. Create component in `archon-ui-main/src/components/`\n2. Add to page in `archon-ui-main/src/pages/`\n3. Include any new API calls in services\n4. Add tests in `archon-ui-main/test/`\n\n### Debug MCP connection issues\n\n1. Check MCP health: `curl http://localhost:8051/health`\n2. View MCP logs: `docker-compose logs archon-mcp`\n3. Test tool execution via UI MCP page\n4. Verify Supabase connection and credentials\n\n## Code Quality Standards\n\nWe enforce code quality through automated linting and type checking:\n\n- **Python 3.12** with 120 character line length\n- **Ruff** for linting - checks for errors, warnings, unused imports, and code style\n- **Mypy** for type checking - ensures type safety across the codebase\n- **Auto-formatting** on save in IDEs to maintain consistent style\n- Run `uv run ruff check` and `uv run mypy src/` locally before committing\n\n## MCP Tools Available\n\nWhen connected to Cursor/Windsurf:\n\n- `archon:perform_rag_query` - Search knowledge base\n- `archon:search_code_examples` - Find code snippets\n- `archon:manage_project` - Project operations\n- `archon:manage_task` - Task management\n- `archon:get_available_sources` - List knowledge sources\n\n## Important Notes\n\n- Projects feature is optional - toggle in Settings UI\n- All services communicate via HTTP, not gRPC\n- HTTP polling handles all updates (Socket.IO removed)\n- Frontend uses Vite proxy for API calls in development\n- Python backend uses `uv` for dependency management\n- Docker Compose handles service orchestration\n- we use tanstack query NO PROP DRILLING! refacring in progress!\n"}
{"type": "file", "path": "/Users/ciarancox/Archon/PRPs/templates/prp_base.md", "relpath": "PRPs/templates/prp_base.md", "size": 10161, "sha256": "b09e9ad32a46e436b0bb7e60fd8e4627bf746145ce467487af663c134e50d556", "created_at": "2025-09-11T20:07:54.028480+00:00", "content": "name: \"Base PRP Template v3 - Implementation-Focused with Precision Standards\"\ndescription: |\n\n---\n\n## Goal\n\n**Feature Goal**: [Specific, measurable end state of what needs to be built]\n\n**Deliverable**: [Concrete artifact - API endpoint, service class, integration, etc.]\n\n**Success Definition**: [How you'll know this is complete and working]\n\n## User Persona (if applicable)\n\n**Target User**: [Specific user type - developer, end user, admin, etc.]\n\n**Use Case**: [Primary scenario when this feature will be used]\n\n**User Journey**: [Step-by-step flow of how user interacts with this feature]\n\n**Pain Points Addressed**: [Specific user frustrations this feature solves]\n\n## Why\n\n- [Business value and user impact]\n- [Integration with existing features]\n- [Problems this solves and for whom]\n\n## What\n\n[User-visible behavior and technical requirements]\n\n### Success Criteria\n\n- [ ] [Specific measurable outcomes]\n\n## All Needed Context\n\n### Context Completeness Check\n\n_Before writing this PRP, validate: \"If someone knew nothing about this codebase, would they have everything needed to implement this successfully?\"_\n\n### Documentation & References\n\n```yaml\n# MUST READ - Include these in your context window\n- url: [Complete URL with section anchor]\n  why: [Specific methods/concepts needed for implementation]\n  critical: [Key insights that prevent common implementation errors]\n\n- file: [exact/path/to/pattern/file.py]\n  why: [Specific pattern to follow - class structure, error handling, etc.]\n  pattern: [Brief description of what pattern to extract]\n  gotcha: [Known constraints or limitations to avoid]\n\n- docfile: [PRPs/ai_docs/domain_specific.md]\n  why: [Custom documentation for complex library/integration patterns]\n  section: [Specific section if document is large]\n```\n\n### Current Codebase tree (run `tree` in the root of the project) to get an overview of the codebase\n\n```bash\n\n```\n\n### Desired Codebase tree with files to be added and responsibility of file\n\n```bash\n\n```\n\n### Known Gotchas of our codebase & Library Quirks\n\n```python\n# CRITICAL: [Library name] requires [specific setup]\n# Example: FastAPI requires async functions for endpoints\n# Example: This ORM doesn't support batch inserts over 1000 records\n```\n\n## Implementation Blueprint\n\n### Data models and structure\n\nCreate the core data models, we ensure type safety and consistency.\n\n```python\nExamples:\n - orm models\n - pydantic models\n - pydantic schemas\n - pydantic validators\n\n```\n\n### Implementation Tasks (ordered by dependencies)\n\n```yaml\nTask 1: CREATE src/models/{domain}_models.py\n  - IMPLEMENT: {SpecificModel}Request, {SpecificModel}Response Pydantic models\n  - FOLLOW pattern: src/models/existing_model.py (field validation approach)\n  - NAMING: CamelCase for classes, snake_case for fields\n  - PLACEMENT: Domain-specific model file in src/models/\n\nTask 2: CREATE src/services/{domain}_service.py\n  - IMPLEMENT: {Domain}Service class with async methods\n  - FOLLOW pattern: src/services/database_service.py (service structure, error handling)\n  - NAMING: {Domain}Service class, async def create_*, get_*, update_*, delete_* methods\n  - DEPENDENCIES: Import models from Task 1\n  - PLACEMENT: Service layer in src/services/\n\nTask 3: CREATE src/tools/{action}_{resource}.py\n  - IMPLEMENT: MCP tool wrapper calling service methods\n  - FOLLOW pattern: src/tools/existing_tool.py (FastMCP tool structure)\n  - NAMING: snake_case file name, descriptive tool function name\n  - DEPENDENCIES: Import service from Task 2\n  - PLACEMENT: Tool layer in src/tools/\n\nTask 4: MODIFY src/main.py or src/server.py\n  - INTEGRATE: Register new tool with MCP server\n  - FIND pattern: existing tool registrations\n  - ADD: Import and register new tool following existing pattern\n  - PRESERVE: Existing tool registrations and server configuration\n\nTask 5: CREATE src/services/tests/test_{domain}_service.py\n  - IMPLEMENT: Unit tests for all service methods (happy path, edge cases, error handling)\n  - FOLLOW pattern: src/services/tests/test_existing_service.py (fixture usage, assertion patterns)\n  - NAMING: test_{method}_{scenario} function naming\n  - COVERAGE: All public methods with positive and negative test cases\n  - PLACEMENT: Tests alongside the code they test\n\nTask 6: CREATE src/tools/tests/test_{action}_{resource}.py\n  - IMPLEMENT: Unit tests for MCP tool functionality\n  - FOLLOW pattern: src/tools/tests/test_existing_tool.py (MCP tool testing approach)\n  - MOCK: External service dependencies\n  - COVERAGE: Tool input validation, success responses, error handling\n  - PLACEMENT: Tool tests in src/tools/tests/\n```\n\n### Implementation Patterns & Key Details\n\n```python\n# Show critical patterns and gotchas - keep concise, focus on non-obvious details\n\n# Example: Service method pattern\nasync def {domain}_operation(self, request: {Domain}Request) -> {Domain}Response:\n    # PATTERN: Input validation first (follow src/services/existing_service.py)\n    validated = self.validate_request(request)\n\n    # GOTCHA: [Library-specific constraint or requirement]\n    # PATTERN: Error handling approach (reference existing service pattern)\n    # CRITICAL: [Non-obvious requirement or configuration detail]\n\n    return {Domain}Response(status=\"success\", data=result)\n\n# Example: MCP tool pattern\n@app.tool()\nasync def {tool_name}({parameters}) -> str:\n    # PATTERN: Tool validation and service delegation (see src/tools/existing_tool.py)\n    # RETURN: JSON string with standardized response format\n```\n\n### Integration Points\n\n```yaml\nDATABASE:\n  - migration: \"Add column 'feature_enabled' to users table\"\n  - index: \"CREATE INDEX idx_feature_lookup ON users(feature_id)\"\n\nCONFIG:\n  - add to: config/settings.py\n  - pattern: \"FEATURE_TIMEOUT = int(os.getenv('FEATURE_TIMEOUT', '30'))\"\n\nROUTES:\n  - add to: src/api/routes.py\n  - pattern: \"router.include_router(feature_router, prefix='/feature')\"\n```\n\n## Validation Loop\n\n### Level 1: Syntax & Style (Immediate Feedback)\n\n```bash\n# Run after each file creation - fix before proceeding\nruff check src/{new_files} --fix     # Auto-format and fix linting issues\nmypy src/{new_files}                 # Type checking with specific files\nruff format src/{new_files}          # Ensure consistent formatting\n\n# Project-wide validation\nruff check src/ --fix\nmypy src/\nruff format src/\n\n# Expected: Zero errors. If errors exist, READ output and fix before proceeding.\n```\n\n### Level 2: Unit Tests (Component Validation)\n\n```bash\n# Test each component as it's created\nuv run pytest src/services/tests/test_{domain}_service.py -v\nuv run pytest src/tools/tests/test_{action}_{resource}.py -v\n\n# Full test suite for affected areas\nuv run pytest src/services/tests/ -v\nuv run pytest src/tools/tests/ -v\n\n# Coverage validation (if coverage tools available)\nuv run pytest src/ --cov=src --cov-report=term-missing\n\n# Expected: All tests pass. If failing, debug root cause and fix implementation.\n```\n\n### Level 3: Integration Testing (System Validation)\n\n```bash\n# Service startup validation\nuv run python main.py &\nsleep 3  # Allow startup time\n\n# Health check validation\ncurl -f http://localhost:8000/health || echo \"Service health check failed\"\n\n# Feature-specific endpoint testing\ncurl -X POST http://localhost:8000/{your_endpoint} \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\"test\": \"data\"}' \\\n  | jq .  # Pretty print JSON response\n\n# MCP server validation (if MCP-based)\n# Test MCP tool functionality\necho '{\"method\": \"tools/call\", \"params\": {\"name\": \"{tool_name}\", \"arguments\": {}}}' | \\\n  uv run python -m src.main\n\n# Database validation (if database integration)\n# Verify database schema, connections, migrations\npsql $DATABASE_URL -c \"SELECT 1;\" || echo \"Database connection failed\"\n\n# Expected: All integrations working, proper responses, no connection errors\n```\n\n### Level 4: Creative & Domain-Specific Validation\n\n```bash\n# MCP Server Validation Examples:\n\n# Playwright MCP (for web interfaces)\nplaywright-mcp --url http://localhost:8000 --test-user-journey\n\n# Docker MCP (for containerized services)\ndocker-mcp --build --test --cleanup\n\n# Database MCP (for data operations)\ndatabase-mcp --validate-schema --test-queries --check-performance\n\n# Custom Business Logic Validation\n# [Add domain-specific validation commands here]\n\n# Performance Testing (if performance requirements)\nab -n 100 -c 10 http://localhost:8000/{endpoint}\n\n# Security Scanning (if security requirements)\nbandit -r src/\n\n# Load Testing (if scalability requirements)\n# wrk -t12 -c400 -d30s http://localhost:8000/{endpoint}\n\n# API Documentation Validation (if API endpoints)\n# swagger-codegen validate -i openapi.json\n\n# Expected: All creative validations pass, performance meets requirements\n```\n\n## Final Validation Checklist\n\n### Technical Validation\n\n- [ ] All 4 validation levels completed successfully\n- [ ] All tests pass: `uv run pytest src/ -v`\n- [ ] No linting errors: `uv run ruff check src/`\n- [ ] No type errors: `uv run mypy src/`\n- [ ] No formatting issues: `uv run ruff format src/ --check`\n\n### Feature Validation\n\n- [ ] All success criteria from \"What\" section met\n- [ ] Manual testing successful: [specific commands from Level 3]\n- [ ] Error cases handled gracefully with proper error messages\n- [ ] Integration points work as specified\n- [ ] User persona requirements satisfied (if applicable)\n\n### Code Quality Validation\n\n- [ ] Follows existing codebase patterns and naming conventions\n- [ ] File placement matches desired codebase tree structure\n- [ ] Anti-patterns avoided (check against Anti-Patterns section)\n- [ ] Dependencies properly managed and imported\n- [ ] Configuration changes properly integrated\n\n### Documentation & Deployment\n\n- [ ] Code is self-documenting with clear variable/function names\n- [ ] Logs are informative but not verbose\n- [ ] Environment variables documented if new ones added\n\n---\n\n## Anti-Patterns to Avoid\n\n- ❌ Don't create new patterns when existing ones work\n- ❌ Don't skip validation because \"it should work\"\n- ❌ Don't ignore failing tests - fix them\n- ❌ Don't use sync functions in async context\n- ❌ Don't hardcode values that should be config\n- ❌ Don't catch all exceptions - be specific\n"}
{"type": "file", "path": "/Users/ciarancox/Archon/Makefile", "relpath": "Makefile", "size": 4676, "sha256": "4daffe1f6ee6d7f7bcb4abc6fc34c4ff1ead7726871456e102fa40b97e893eaa", "created_at": "2025-09-11T20:07:54.058217+00:00", "content": "# Archon Makefile - Simple, Secure, Cross-Platform\nSHELL := /bin/bash\n.SHELLFLAGS := -ec\n\n# Docker compose command - prefer newer 'docker compose' plugin over standalone 'docker-compose'\nCOMPOSE ?= $(shell docker compose version >/dev/null 2>&1 && echo \"docker compose\" || echo \"docker-compose\")\n\n.PHONY: help dev dev-docker stop test test-fe test-be lint lint-fe lint-be clean install check\n\nhelp:\n\t@echo \"Archon Development Commands\"\n\t@echo \"===========================\"\n\t@echo \"  make dev        - Backend in Docker, frontend local (recommended)\"\n\t@echo \"  make dev-docker - Everything in Docker\"\n\t@echo \"  make stop       - Stop all services\"\n\t@echo \"  make test       - Run all tests\"\n\t@echo \"  make test-fe    - Run frontend tests only\"\n\t@echo \"  make test-be    - Run backend tests only\"\n\t@echo \"  make lint       - Run all linters\"\n\t@echo \"  make lint-fe    - Run frontend linter only\"\n\t@echo \"  make lint-be    - Run backend linter only\"\n\t@echo \"  make clean      - Remove containers and volumes\"\n\t@echo \"  make install    - Install dependencies\"\n\t@echo \"  make check      - Check environment setup\"\n\t@echo \"\\nContext Bundle Utilities\"\n\t@echo \"  make bundle-new PURPOSE=\\\"...\\\"       - Create a new context bundle and set it current\"\n\t@echo \"  make bundle-read PATH=path/to/file     - Append a file's contents to current bundle\"\n\t@echo \"  make bundle-findings BULLETS='[\"Risk A\",\"Risk B\"]' - Append findings bullets\"\n\t@echo \"  make bundle-load [BUNDLE=dir]          - Print consolidated bundle summary (default current)\"\n\n# Install dependencies\ninstall:\n\t@echo \"Installing dependencies...\"\n\t@cd archon-ui-main && npm install\n\t@cd python && uv sync --group all --group dev\n\t@echo \"✓ Dependencies installed\"\n\n# Check environment\ncheck:\n\t@echo \"Checking environment...\"\n\t@node -v >/dev/null 2>&1 || { echo \"✗ Node.js not found (require Node 18+).\"; exit 1; }\n\t@node check-env.js\n\t@echo \"Checking Docker...\"\n\t@docker --version > /dev/null 2>&1 || { echo \"✗ Docker not found\"; exit 1; }\n\t@$(COMPOSE) version > /dev/null 2>&1 || { echo \"✗ Docker Compose not found\"; exit 1; }\n\t@echo \"✓ Environment OK\"\n\n\n# Hybrid development (recommended)\ndev: check\n\t@echo \"Starting hybrid development...\"\n\t@echo \"Backend: Docker | Frontend: Local with hot reload\"\n\t@$(COMPOSE) --profile backend up -d --build\n\t@set -a; [ -f .env ] && . ./.env; set +a; \\\n\techo \"Backend running at http://$${HOST:-localhost}:$${ARCHON_SERVER_PORT:-8181}\"\n\t@echo \"Starting frontend...\"\n\t@cd archon-ui-main && \\\n\tVITE_ARCHON_SERVER_PORT=$${ARCHON_SERVER_PORT:-8181} \\\n\tVITE_ARCHON_SERVER_HOST=$${HOST:-} \\\n\tnpm run dev\n\n# Full Docker development\ndev-docker: check\n\t@echo \"Starting full Docker environment...\"\n\t@$(COMPOSE) --profile full up -d --build\n\t@echo \"✓ All services running\"\n\t@echo \"Frontend: http://localhost:3737\"\n\t@echo \"API: http://localhost:8181\"\n\n# Stop all services\nstop:\n\t@echo \"Stopping all services...\"\n\t@$(COMPOSE) --profile backend --profile frontend --profile full down\n\t@echo \"✓ Services stopped\"\n\n# Run all tests\ntest: test-fe test-be\n\n# Run frontend tests\ntest-fe:\n\t@echo \"Running frontend tests...\"\n\t@cd archon-ui-main && npm test\n\n# Run backend tests\ntest-be:\n\t@echo \"Running backend tests...\"\n\t@cd python && uv run pytest\n\n# Run all linters\nlint: lint-fe lint-be\n\n# Run frontend linter\nlint-fe:\n\t@echo \"Linting frontend...\"\n\t@cd archon-ui-main && npm run lint\n\n# Run backend linter\nlint-be:\n\t@echo \"Linting backend...\"\n\t@cd python && uv run ruff check --fix\n\n# Clean everything (with confirmation)\nclean:\n\t@echo \"⚠️  This will remove all containers and volumes\"\n\t@read -p \"Are you sure? (y/N) \" -n 1 -r; \\\n\techo; \\\n\tif [[ $$REPLY =~ ^[Yy]$$ ]]; then \\\n\t\t$(COMPOSE) down -v --remove-orphans; \\\n\t\techo \"✓ Cleaned\"; \\\n\telse \\\n\t\techo \"Cancelled\"; \\\n\tfi\n\n.DEFAULT_GOAL := help\n\n# ===================== Context Bundle Targets =====================\n\n.PHONY: bundle-new bundle-read bundle-findings bundle-load\n\nbundle-new:\n\t@if [ -z \"$(PURPOSE)\" ]; then echo \"ERROR: PURPOSE is required. Example: make bundle-new PURPOSE=\\\"Kickoff context\\\"\"; exit 1; fi\n\t@mkdir -p agents/context-bundles\n\t@python3 scripts/context_bundle_writer.py new --purpose \"$(PURPOSE)\"\n\nbundle-read:\n\t@if [ -z \"$(PATH)\" ]; then echo \"ERROR: PATH is required. Example: make bundle-read PATH=README.md\"; exit 1; fi\n\t@python3 scripts/context_bundle_writer.py read --path \"$(PATH)\"\n\nbundle-findings:\n\t@if [ -z \"$(BULLETS)\" ]; then echo \"ERROR: BULLETS is required. Example: make bundle-findings BULLETS='[\\\"Risk A\\\",\\\"Risk B\\\"]'\"; exit 1; fi\n\t@python3 scripts/context_bundle_writer.py findings --bullets '$(BULLETS)'\n\nbundle-load:\n\t@python3 scripts/load_bundle.py $(if $(BUNDLE),--bundle \"$(BUNDLE)\")\n"}
{"type": "findings", "bullets": ["Risk A", "Risk B"], "created_at": "2025-09-11T20:07:59.260201+00:00"}
{"type": "file", "path": "/Users/ciarancox/Archon/agents/context-bundles/20250911-200710-kickoff-context/artifacts/keyword_success_criteria.json", "relpath": "agents/context-bundles/20250911-200710-kickoff-context/artifacts/keyword_success_criteria.json", "size": 22552, "sha256": "81ee35944f11762ad453c077f684ad3465f5b0e36fc770db8680bb17eb56678c", "created_at": "2025-09-11T20:16:55.644627+00:00", "content": "{\"success\":true,\"results\":[{\"id\":25561,\"url\":\"file://PRP.md\",\"chunk_number\":0,\"content\":\"This chunk contains the full initial section of the \\\"PRP — Mastering Context Engineering for Agent Performance\\\" document, including the owner, date, goal, summary, success criteria, scope, and non-goals. It provides a comprehensive overview of the best practices and objectives for improving agent performance through context reduction and delegation strategies.\\n\\nCHUNK 2: This chunk is a partial excerpt of the same document, specifically the beginning of the \\\"Summary\\\" section, which is cut off. It situates within the overall document as an incomplete part of the introductory explanation of the PRP, likely intended to elaborate on the \\\"Reduce\\\" principle before the full details are provided.\\n\\nCHUNK 3: This chunk details a specific phase (\\\"Phase B — Delegate (Sub‑agents)\\\") focusing on the process of sub-agent document/web ingestion, including the workflow steps, command usage, and the gate condition. It situates within the document as a procedural example of delegation practices for handling token-heavy\\\\n\\\\n# PRP — Mastering Context Engineering for Agent Performance (R&D Best Practices)\\n\\n**Owner:** Ciaran Cox  \\n**Date:** 2025‑09‑10  \\n**Goal:** Implement a repeatable Reduce & Delegate (R&D) context‑engineering workflow that produces faster, more reliable, and cheaper agent runs by shrinking the primary context window and offloading heavy work to focused agents.\\n\\n## 1) Summary (Why / What)\\nA focused agent is a performant agent. This PRP operationalizes R&D best practices:\\n- **Reduce** what enters the primary agent’s context at boot and during loops.\\n- **Delegate** token‑heavy tasks to sub‑agents or background primary agents and persist outcomes as files/bundles.\\n\\n**Desired outcome:** Boot with a slim, universal memory; load only task‑specific tools/context on demand; orchestrate sub‑agents/background agents for heavy I/O; maintain replayable **context bundles** so work continues cleanly after context explosions.\\n\\n## 2) Success Criteria (Definition of Done)\\n1. **Boot budget:** Primary agent starts with ≥90% free context; always‑on memory ≤500 tokens.\\n2. **MCP hygiene:** No default MCP servers autoloaded; task runs pass in an explicit MCP config.\\n3. **Priming over memory:** Task types use **prime commands** (bug/feature/docs/CC) to read only the minimal files needed.\\n4. **Delegation:** Web/doc reads and other token‑heavy steps run in **sub‑agents** or **background primary agents** and write artifacts to disk.\\n5. **Context bundles:** Each significant run writes an append‑only bundle (prompt + reads + key findings). A new agent can **/load** a bundle to remount state to ~70% without re‑reading everything.\\n6. **Reporting:** Background agents write to a report file and rename it on completion.\\n\\n## 3) Scope / Non‑Goals\\n- **In scope:** Agent context hygiene, MCP configuration discipline, priming commands, sub‑agent workflows, background agent delegation, context bundle logging, Makefile/CLI wrappers, CI lint.\\n- **Out of scope:** New product features beyond these workflow changes; model/provider swaps; IDE migration.\\n\\n## 4) Inputs & Artifacts\\n**Inputs**\\n- Existing repo and Claude‑style slash‑command support.\\n- Optional MCP servers (e.g., web fetch / Firecrawl) available but **not** autoloaded.\\n\\n**Artifacts produced**\\n- `memory/concise.md` — tiny universal memory file.\\n- `.claude/commands/prime_*.md` — reusable primes (bug, feature, docs, cc).\\n- `.claude/commands/background.md` — fires a background instance + report file.\\n- `.claude/commands/load_ai_docs.md` — sub‑agent doc ingestion.\\n- `.claude/commands/load_bundle.md` — remount prior state.\\n- `agents/context-bundles/…` — append‑only run trails.\\n- `reports/**` — status & outputs from background/prime runs.\\n- `configs/mcp/firecrawl.json` — example strict per‑task MCP config.\\n- `scripts/lint_memory.py` — CI lint for memory size.\\n- `scripts/context_bundle_writer.py`, `scripts/load_bundle.py` — bundle utilities.\\n- `Makefile` — convenience wrappers.\\n- `.github/workflows/lint-memory.yml` — CI enforcement.\\n\\n## 5) Constraints & Risks\\n- **Risk (coordination):** Sub‑agent chatter or oversized outputs can re‑bloat context.  \\n  **Mitigation:** Return **summaries + file paths**, not raw dumps.\\n- **Risk (memory creep):** Teams expand universal memory over time.  \\n  **Mitigation:** Hard cap lines/tokens; everything else moves to primes.\\n- **Risk (tool sprawl):** Loading many MCP servers “just in case.”  \\n  **Mitigation:** Enforce explicit per‑task MCP configs.\\n\\n## 6) Implementation Plan (R&D in action)\\n\\n### Phase A — Reduce\\n1. **Kill default MCP autoload**\\n   - Remove `default.mcp.json` (or equivalent).\\n   - Create per‑task configs (e.g., `configs/mcp/firecrawl.json`).\\n   - Run tasks with a strict flag in your tool (e.g., `--strict-mcp-config <path>`).\\n\\n2. **Slim universal memory**\\n   - Replace the giant always‑on memory file with `memory/concise.md` (≤50 lines).\\n   - Keep only **universal, always‑true** rules (style, output format, safety, short glossary).\\n   - Add a CI check that fails if the file exceeds token/line caps.\\n\\n3. **Adopt context priming**\\n   - Add primes:\\n     - `.claude/commands/prime_bug.md`\\n     - `.claude/commands/prime_feature.md`\\n     - `.claude/commands/prime_docs.md`\\n     - `.claude/commands/prime_cc.md`\\n   - **Prime template (all primes follow this):**\\n     - **Purpose** — one‑line intent.\\n     - **Run** — minimal steps for this task type.\\n     - **Read** — explicit file list/globs (keep tiny).\\n     - **Report** — where to write status/summary.\\n\\n**Gate A:** Boot context free ≥90%; memory ≤500 tokens; no MCP servers loaded by default.\",\"metadata\":{\"url\":\"file://PRP.md\",\"tags\":[\"prp\",\"project\"],\"source\":\"file_PRP_md_6032efe2\",\"headers\":\"# PRP — Mastering Context Engineering for Agent Performance (R&D Best Practices); ## 1) Summary (Why / What); ## 2) Success Criteria (Definition of Done); ## 3) Scope / Non‑Goals; ## 4) Inputs & Artifacts; ## 5) Constraints & Risks; ## 6) Implementation Plan (R&D in action); ### Phase A — Reduce\",\"filename\":\"PRP.md\",\"has_code\":false,\"has_links\":false,\"source_id\":\"file_PRP_md_6032efe2\",\"char_count\":4563,\"chunk_size\":5580,\"line_count\":78,\"word_count\":610,\"chunk_index\":0,\"source_type\":\"file\",\"knowledge_type\":\"business\",\"contextual_embedding\":true},\"source_id\":\"file_PRP_md_6032efe2\",\"similarity\":0.200377359986305,\"match_type\":\"keyword\"},{\"id\":19905,\"url\":\"https://synergyspanish.com/gd/fts-in-spanish/\",\"chunk_number\":3,\"content\":\"Promotional content introducing a Spanish learning system that emphasizes simple patterns and natural conversation, targeting individuals frustrated with traditional methods, with a special offer and personal story from Marcus Santamaria.\\n\\nCHUNK 2: Additional promotional details highlighting flexible learning options (e.g., in car, exercising), bonuses like transcripts and word lists, and immediate access to the program for a low price, reinforcing the ease and convenience of the system.\\n\\nCHUNK 3: Repetition of the promotional message, emphasizing the affordability, guarantee, and the approach's focus on natural language blending, with personal background from Marcus Santamaria.\\n\\nCHUNK 4: Website navigation and links to blog, courses, testimonials, about, contact, and login, along with sample video content, indicating the structure of the site and available resources.\\n\\nCHUNK 5: Similar website navigation and promotional content for the Spanish learning program, with links to videos, special offers, and testimonials, emphasizing the program's accessibility and success stories.\\n\\nCHUNK 6: User comments and testimonials expressing gratitude and positive experiences with the program, along with encouragement and personal reflections, adding social proof and engagement.\\n\\nCHUNK 7: Repeated website navigation, promotional offers, and testimonials, reinforcing the program's value and community feedback, with some user comments about progress and motivation.\\n\\nCHUNK 8: Website navigation, promotional content, and sample videos for different Spanish levels, emphasizing the simplicity and variety of learning resources, with user comments on program effectiveness.\\n\\nCHUNK 9: Promotional message about a large Spanish coaching package giveaway, addressing common barriers to learning, and sharing Marcus Santamaria’s personal story of overcoming difficulties, aimed at motivating potential learners.\\n\\nCHUNK 10: Details about a scholarship contest, including categories and entry questions, offering access to a high-value program, and encouraging participation through personal success stories.\\n\\nCHUNK 11: Explanation of scholarship benefits, entry criteria, and motivational messaging about overcoming learning barriers, with a focus on personal transformation and success.\\n\\nCHUNK 12: Reiteration of the scholarship contest, emphasizing the importance of overcoming mental blocks and financial barriers, with testimonials and personal stories of progress.\\n\\nCHUNK 13: Personal testimonial from a learner expressing hope, gratitude, and the impact of the program on confidence and future plans, illustrating real-life success.\\n\\nCHUNK 14: User comments and testimonials praising the program, sharing personal progress, and expressing hope or gratitude, adding social proof and community engagement.\\n\\nCHUNK 15: Personal aspirations of a learner wanting to help others and improve their Spanish for professional reasons, highlighting the practical benefits of the program.\\n\\nCHUNK 16: Comments from users about their motivation, personal goals, and the value of the lessons, with some suggestions for more interactive content, emphasizing community and ongoing learning.\\n\\nCHUNK 17: Promotion of a Spanish coaching package giveaway, with personal stories of overcoming barriers, and encouragement to participate, along with links to additional resources and success stories.\\n\\nCHUNK 18: Testimonials from learners showing significant progress and increased confidence, with future travel plans, reinforcing the effectiveness of the program.\\n\\nCHUNK 19: Repeated promotional content about the coaching package giveaway, emphasizing overcoming common barriers like age, finances, and confidence, with personal stories of struggle and success.\\n\\nCHUNK 20: Comments from users about their professional and personal goals related to learning Spanish, highlighting the program’s practical applications and community support.\\n\\nCHUNK 21: Personal stories from learners about their progress, intentions to help others, and reflections on their language journey, illustrating motivation and community impact.\\n\\nCHUNK 22: Comments and questions about the program’s suitability and interest in Spanish learning paths, with some users expressing enthusiasm and others seeking refreshers or more advanced content.\\n\\nCHUNK 23: Promotion of different levels of Spanish learning videos, emphasizing simplicity and accessibility, with links to free resources for beginners to advanced learners.\\n\\nCHUNK 24: Additional links to Spanish lessons at various levels, sharing free video resources, and encouraging ongoing practice, with community sharing and engagement.\\n\\nCHUNK 25: Reiteration of the program’s focus on simple, straightforward Spanish learning, with links to free videos for different proficiency levels, and social sharing options.\\\\n\\\\nPick up Spanish in your car, while you exercise, or as you work.\\n✅ **BONUS 2: PDF Transcripts** Acquire more Spanish in less time with every word of every lesson right at your fingertips.\\n✅ **BONUS 3: Instant Spanish Word Lists** – The easy way to pick up 1066 Spanish words.\\n**_When you order, you’ll receive IMMEDIATE ACCESS to the FULL PROGRAM… everything you need to get started with Spanish_**\\n[Start Speaking Spanish Now $7](https://checkout.synergyspanish.com/how-to-go-from-failure-to-success/?coupon=NEWSTUDENT5&ref=ga)\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20200%200'%3E%3C/svg%3E)\\nOne Time Payment – Lifetime Access – 60 Day Guarantee\\n_*Limited Time Offer Of $7 (One-Time Payment) Normally $19.95_\\nHow Do I Know This Will Work For Me?\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20582%20325'%3E%3C/svg%3E)\\nIf you can speak English, you can speak Spanish.\\nThis program takes advantage of speaking patterns that are already hard wired into your brain.\\nYou just plug and play a handful of simple language patterns and Spanish starts to flow.\\n✅ It’s natural.\\n✅ It’s easy.\\n✅ It’s fun.\\nAnd best of all it works in real conversations…\\nIt’s so exciting and rewarding when you use your Spanish in daily life.\\nSpanish speakers are delighted and helpful when you speak to them in their language.\\nIt’s a joy chatting with the baristas in the cafes, the vendors in the markets and the locals at the town square.\\nCheck out the comments below from people just like you who now enjoy speaking this beautiful language.\\nWhat My Students ARE SAYING…\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20477%20235'%3E%3C/svg%3E)\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20483%20202'%3E%3C/svg%3E)\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20479%20122'%3E%3C/svg%3E)\\n![](data:image/svg+xml,%3Csvg%20xmlns='http://www.w3.org/2000/svg'%20viewBox='0%200%20473%20158'%3E%3C/svg%3E)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.18.01-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.04.03-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.21.53-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.39.49-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.53.12-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.20.35-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.55.32-pm-2.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.56.18-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.04.54-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.10.56-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.18.21-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.46.14-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.40.39-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.09.08-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.39.05-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.56.58-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.00.28-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.41.05-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.51.35-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.51.26-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.04.17-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-5.52.41-pm-2.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.00.37-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.00.44-pm-2.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.00.54-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.09.19-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.10.41-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.11.25-pm.png)\\n![](https://synergyspanish.com/wp-content/uploads/2020/07/Screen-Shot-2019-06-26-at-6.12.46-pm.png)\\n![](https://synergysp\",\"metadata\":{\"url\":\"https://synergyspanish.com/gd/fts-in-spanish/\",\"tags\":[],\"title\":\"\",\"source_id\":\"bb70a2ccd012f308\",\"char_count\":4999,\"chunk_size\":9829,\"crawl_type\":\"webpage\",\"word_count\":268,\"chunk_index\":3,\"description\":\"\",\"knowledge_type\":\"technical\",\"contextual_embedding\":true},\"source_id\":\"bb70a2ccd012f308\",\"similarity\":0.0177777782082558,\"match_type\":\"keyword\"},{\"id\":1252,\"url\":\"https://circle.so/blog/brand-messaging-framework\",\"chunk_number\":4,\"content\":\"The point of this is not to feel bad about yourself or your message if it sounds like the above. Just because your message isn’t up to snuff, doesn't mean that what you’re offering isn't valuable. \\nIt’s a process that requires refining over time based on your experience, growth, and targeting. \\nJust look at Maya’s.\\n![Maya Elious' brand messaging over the years](https://cdn.builder.io/api/v1/image/assets%2Fd5e2d72a033944e1a916c5c34902a1ff%2F9fbee488a0af4ef697833b8435fc63df?width=866)\\n“Good messaging is not about people-pleasing,” says Maya. “It’s about communicating the value that you add to a specific industry that you have expertise in. Stop trying to save everyone.”\\n## The playbook\\nIf you’ve never thought about how your brand comes across online, or used to think it’s just “marketing fluff”—think again. \\nThe entrepreneurs (and millionaires) from our past playbooks—Codie Sanchez and Ali Abdaal—have laser-focused messaging across their entire web presence. They know who they’re speaking to, what’s special about what they bring to the table, and how they uniquely solve their target audience’s problems.\\nSo, how do you get your brand’s messaging to millionaire status?\\n### Maya’s Dating Method\\n“Your messaging, like dating, is trial & error.” - Maya Elious\\nWhen you’re dating, your headspace will change how you approach choosing partners: **Are you desperate—or picky?**\\nWhen you’re desperate or unsure about yourself, you don’t have a filter. You date anybody.\\n“In my 20s, my standards were way lower. It was like, if you like Jesus and tequila, we can date!” says Maya.\\n“But with time, as you get more confident in who you are and really clear on what type and quality of person you want? You start to quickly exclude unfit candidates.”\\n![Maya's must haves for dating and clients](https://cdn.builder.io/api/v1/image/assets%2Fd5e2d72a033944e1a916c5c34902a1ff%2Ff35e5bb1673948278782e6a72fea9773?width=866)\\nWhen you’re confident about what you want and what you bring to the table, your options decrease because not everybody fits your criteria. \\nThis is a good thing—and it comes with time, experience, and wisdom.\\n“There were like 4 people left in Atlanta for me,” said Maya. “But I would rather have a conversation with four quality people than waste my energy talking to 16 bad-fit people. This is how I want you to think about your messaging.”\\n### 5 Tips for applying the Dating Method\\nThe goal with crystal clear messaging is to feel SO confident selling your services or courses, you worry about your potential customers missing out on the transformations you could get for them. \\n  1. **Narrow your niche**. Set yourself up for success by [going niche](https://circle.so/blog/how-to-find-your-niche). The top 3 most profitable industries are health, wealth, and self. \\n     * Health: Holistic wellness, personal training, weight loss, nutrition From wellness coach > holistic coach who helps people lose weight naturally. \\n     * Wealth: Money mindset, career coaching From career coach > Career coach for mid-career professionals who want to increase their salary by $25k \\n     * Self & relationships: Romantic, familial, self-relationships. From relationship coach > Relationship coach for those in relationships 7+ years \\n  2. **Define your audience**. Your target customer is either a version of who you once were, or a group of people your heart is drawn to and for whom you can solve a very specific problem. If you’re confused about who your audience is, take a look back in time 5-7 years to who you used to be. \\n  3. **Position your value**. Value is subjective. Just because you think something is valuable, doesn’t mean someone else will. That’s why to show value, you have to acknowledge what your customer wants. If you want to know whether your ideal customer thinks your messaging or offer is valuable… you have to understand: \\n     * What do they deeply desire? \\n     * What is the pain point that they're dealing with? (As a result of not having what they want.) \\n     * What is the transformation or outcome that they're looking for when they come to you? What’s the consequence of not getting their desire or getting rid of their pain? \\n  4. **Package your offer**. [Your offer](https://circle.so/blog/building-a-core-offer)—what your customer will buy—can be free to start, and paid to follow. The key is keeping it super clear and “you HAVE TO SAY THE PRICE!” says Maya, because if you don’t have something to sell, you can’t monetize your message. \\n  5. **Differentiate your brand**. It’s important to start out in a competitive and saturated market. If it’s saturated, that means you’re in a profitable industry. What can make you different? \\n     * People you target\\n     * Level of experience\\n     * Brand story\\n     * Statistics of your company\",\"metadata\":{\"url\":\"https://circle.so/blog/brand-messaging-framework\",\"tags\":[],\"title\":\"\",\"source_id\":\"4012484c9956f5e7\",\"char_count\":4794,\"chunk_size\":4794,\"crawl_type\":\"webpage\",\"word_count\":737,\"chunk_index\":4,\"description\":\"\",\"knowledge_type\":\"technical\"},\"source_id\":\"4012484c9956f5e7\",\"similarity\":0.000943396240472794,\"match_type\":\"keyword\"}],\"query\":\"success criteria\",\"source\":null,\"match_count\":20,\"total_found\":3,\"execution_path\":\"keyword_only\"}"}
{"type": "file", "path": "/Users/ciarancox/Archon/agents/context-bundles/20250911-200710-kickoff-context/artifacts/keyword_phase_b_delegate.json", "relpath": "agents/context-bundles/20250911-200710-kickoff-context/artifacts/keyword_phase_b_delegate.json", "size": 10422, "sha256": "14db8e2e8a610cb845d5add2cfe03ecef97d356b6cc7aa947c09eb4d5b2117f5", "created_at": "2025-09-11T20:16:55.678941+00:00", "content": "{\"success\":true,\"results\":[{\"id\":25562,\"url\":\"file://PRP.md\",\"chunk_number\":1,\"content\":\"### Phase B — Delegate (Sub‑agents)\\n4. **Sub‑agent doc/web ingestion**\\n   - Use `.claude/commands/load_ai_docs.md` with a **system‑prompted** workflow:\\n     **Purpose → Variables → Workflow → Report format**.\\n   - Steps: primary agent reads a seed file → spawns N sub‑agents to fetch/scrape docs (one URL per sub‑agent) → each writes outputs to `agents/ai-docs/…` and a concise summary.\\n   - Ensure tokens burn inside sub‑agents; primary receives only summaries + paths.\\n\\n**Gate B:** Primary context remains under ~10k tokens during ingestion; outputs saved; summaries generated.\\n\\n### Phase C — Advanced R&D (Bundles + Background)\\n5. **Context bundles (append‑only logs)**\\n   - Use hooks or the provided scripts so each **read/search/prompt** appends to `agents/context-bundles/<timestamp>_<session>/bundle.jsonl`:\\n     - `prompt` (purpose + arguments)\\n     - `reads` (deduped file list)\\n     - `key_findings` (concise bullets)\\n   - Use the provided loader script to dedupe reads, reconstruct key findings, and print a **one‑screen recap**.\\n\\n6. **Background primary agent delegation**\\n   - `.claude/commands/background.md` starts a detached agent using arguments (model, task, report file path, working dir).\\n   - The background agent writes progress to `reports/<task>/<timestamp>.report.md` and **renames** it to `…_completed.md` when done.\\n\\n**Gate C:** Able to remount a blown context to ~70% state from a bundle; background agent produces a completed report file.\\n\\n## 7) Validation & QA Gates\\n- **Gate A (Reduce):** Boot audit shows ≥90% free, ≤500‑token memory, 0 MCP servers loaded.\\n- **Gate B (Delegate):** Sub‑agent run saves N outputs; primary agent token use stays under the cap; report includes URL → file mapping.\\n- **Gate C (Bundles/Background):** Bundle loader reconstructs prior state with deduped reads; background report file is present and renamed to `…_completed.md`.\\n- **Smoke tests:** Run a sample “docs refresh” and “quick plan” to verify end‑to‑end R&D flow.\\n\\n## 8) Metrics to Track\\n- Startup tokens (before/after).  \\n- Total tokens burned **in primary** vs **in sub/background agents**.  \\n- Latency per task stage (prime → ingest → plan → implement).  \\n- One‑shot success rate of out‑loop tasks.  \\n- Number of re‑primes required.\\n\\n## 9) Rollout & Ops\\n- Land the memory and command changes on a feature branch; run against one repo for 48 hours; compare metrics.  \\n- If gains ≥20% primary‑token reduction and stable success rate, roll to all projects.  \\n- Add a weekly lint to block memory file growth; review MCP configs in PRs.\\n\\n## 10) Team Playbook\\n- Keep the universal memory tiny; everything else is a **prime**.  \\n- Never autoload MCP servers; pass explicit configs per run.  \\n- Use sub‑agents for web/doc I/O and heavy reads.  \\n- Always write a bundle; reload bundles when the window explodes.  \\n- Prefer background delegation to get out of the loop.\",\"metadata\":{\"url\":\"file://PRP.md\",\"tags\":[\"prp\",\"project\"],\"source\":\"file_PRP_md_6032efe2\",\"headers\":\"### Phase B — Delegate (Sub‑agents); ### Phase C — Advanced R&D (Bundles + Background); ## 7) Validation & QA Gates; ## 8) Metrics to Track; ## 9) Rollout & Ops; ## 10) Team Playbook\",\"filename\":\"PRP.md\",\"has_code\":false,\"has_links\":false,\"source_id\":\"file_PRP_md_6032efe2\",\"char_count\":2880,\"chunk_size\":2880,\"line_count\":47,\"word_count\":427,\"chunk_index\":1,\"source_type\":\"file\",\"knowledge_type\":\"business\"},\"source_id\":\"file_PRP_md_6032efe2\",\"similarity\":0.103779129683971,\"match_type\":\"keyword\"},{\"id\":25561,\"url\":\"file://PRP.md\",\"chunk_number\":0,\"content\":\"This chunk contains the full initial section of the \\\"PRP — Mastering Context Engineering for Agent Performance\\\" document, including the owner, date, goal, summary, success criteria, scope, and non-goals. It provides a comprehensive overview of the best practices and objectives for improving agent performance through context reduction and delegation strategies.\\n\\nCHUNK 2: This chunk is a partial excerpt of the same document, specifically the beginning of the \\\"Summary\\\" section, which is cut off. It situates within the overall document as an incomplete part of the introductory explanation of the PRP, likely intended to elaborate on the \\\"Reduce\\\" principle before the full details are provided.\\n\\nCHUNK 3: This chunk details a specific phase (\\\"Phase B — Delegate (Sub‑agents)\\\") focusing on the process of sub-agent document/web ingestion, including the workflow steps, command usage, and the gate condition. It situates within the document as a procedural example of delegation practices for handling token-heavy\\\\n\\\\n# PRP — Mastering Context Engineering for Agent Performance (R&D Best Practices)\\n\\n**Owner:** Ciaran Cox  \\n**Date:** 2025‑09‑10  \\n**Goal:** Implement a repeatable Reduce & Delegate (R&D) context‑engineering workflow that produces faster, more reliable, and cheaper agent runs by shrinking the primary context window and offloading heavy work to focused agents.\\n\\n## 1) Summary (Why / What)\\nA focused agent is a performant agent. This PRP operationalizes R&D best practices:\\n- **Reduce** what enters the primary agent’s context at boot and during loops.\\n- **Delegate** token‑heavy tasks to sub‑agents or background primary agents and persist outcomes as files/bundles.\\n\\n**Desired outcome:** Boot with a slim, universal memory; load only task‑specific tools/context on demand; orchestrate sub‑agents/background agents for heavy I/O; maintain replayable **context bundles** so work continues cleanly after context explosions.\\n\\n## 2) Success Criteria (Definition of Done)\\n1. **Boot budget:** Primary agent starts with ≥90% free context; always‑on memory ≤500 tokens.\\n2. **MCP hygiene:** No default MCP servers autoloaded; task runs pass in an explicit MCP config.\\n3. **Priming over memory:** Task types use **prime commands** (bug/feature/docs/CC) to read only the minimal files needed.\\n4. **Delegation:** Web/doc reads and other token‑heavy steps run in **sub‑agents** or **background primary agents** and write artifacts to disk.\\n5. **Context bundles:** Each significant run writes an append‑only bundle (prompt + reads + key findings). A new agent can **/load** a bundle to remount state to ~70% without re‑reading everything.\\n6. **Reporting:** Background agents write to a report file and rename it on completion.\\n\\n## 3) Scope / Non‑Goals\\n- **In scope:** Agent context hygiene, MCP configuration discipline, priming commands, sub‑agent workflows, background agent delegation, context bundle logging, Makefile/CLI wrappers, CI lint.\\n- **Out of scope:** New product features beyond these workflow changes; model/provider swaps; IDE migration.\\n\\n## 4) Inputs & Artifacts\\n**Inputs**\\n- Existing repo and Claude‑style slash‑command support.\\n- Optional MCP servers (e.g., web fetch / Firecrawl) available but **not** autoloaded.\\n\\n**Artifacts produced**\\n- `memory/concise.md` — tiny universal memory file.\\n- `.claude/commands/prime_*.md` — reusable primes (bug, feature, docs, cc).\\n- `.claude/commands/background.md` — fires a background instance + report file.\\n- `.claude/commands/load_ai_docs.md` — sub‑agent doc ingestion.\\n- `.claude/commands/load_bundle.md` — remount prior state.\\n- `agents/context-bundles/…` — append‑only run trails.\\n- `reports/**` — status & outputs from background/prime runs.\\n- `configs/mcp/firecrawl.json` — example strict per‑task MCP config.\\n- `scripts/lint_memory.py` — CI lint for memory size.\\n- `scripts/context_bundle_writer.py`, `scripts/load_bundle.py` — bundle utilities.\\n- `Makefile` — convenience wrappers.\\n- `.github/workflows/lint-memory.yml` — CI enforcement.\\n\\n## 5) Constraints & Risks\\n- **Risk (coordination):** Sub‑agent chatter or oversized outputs can re‑bloat context.  \\n  **Mitigation:** Return **summaries + file paths**, not raw dumps.\\n- **Risk (memory creep):** Teams expand universal memory over time.  \\n  **Mitigation:** Hard cap lines/tokens; everything else moves to primes.\\n- **Risk (tool sprawl):** Loading many MCP servers “just in case.”  \\n  **Mitigation:** Enforce explicit per‑task MCP configs.\\n\\n## 6) Implementation Plan (R&D in action)\\n\\n### Phase A — Reduce\\n1. **Kill default MCP autoload**\\n   - Remove `default.mcp.json` (or equivalent).\\n   - Create per‑task configs (e.g., `configs/mcp/firecrawl.json`).\\n   - Run tasks with a strict flag in your tool (e.g., `--strict-mcp-config <path>`).\\n\\n2. **Slim universal memory**\\n   - Replace the giant always‑on memory file with `memory/concise.md` (≤50 lines).\\n   - Keep only **universal, always‑true** rules (style, output format, safety, short glossary).\\n   - Add a CI check that fails if the file exceeds token/line caps.\\n\\n3. **Adopt context priming**\\n   - Add primes:\\n     - `.claude/commands/prime_bug.md`\\n     - `.claude/commands/prime_feature.md`\\n     - `.claude/commands/prime_docs.md`\\n     - `.claude/commands/prime_cc.md`\\n   - **Prime template (all primes follow this):**\\n     - **Purpose** — one‑line intent.\\n     - **Run** — minimal steps for this task type.\\n     - **Read** — explicit file list/globs (keep tiny).\\n     - **Report** — where to write status/summary.\\n\\n**Gate A:** Boot context free ≥90%; memory ≤500 tokens; no MCP servers loaded by default.\",\"metadata\":{\"url\":\"file://PRP.md\",\"tags\":[\"prp\",\"project\"],\"source\":\"file_PRP_md_6032efe2\",\"headers\":\"# PRP — Mastering Context Engineering for Agent Performance (R&D Best Practices); ## 1) Summary (Why / What); ## 2) Success Criteria (Definition of Done); ## 3) Scope / Non‑Goals; ## 4) Inputs & Artifacts; ## 5) Constraints & Risks; ## 6) Implementation Plan (R&D in action); ### Phase A — Reduce\",\"filename\":\"PRP.md\",\"has_code\":false,\"has_links\":false,\"source_id\":\"file_PRP_md_6032efe2\",\"char_count\":4563,\"chunk_size\":5580,\"line_count\":78,\"word_count\":610,\"chunk_index\":0,\"source_type\":\"file\",\"knowledge_type\":\"business\",\"contextual_embedding\":true},\"source_id\":\"file_PRP_md_6032efe2\",\"similarity\":0.101690851151943,\"match_type\":\"keyword\"}],\"query\":\"Phase B — Delegate (Sub‑agents)\",\"source\":null,\"match_count\":20,\"total_found\":2,\"execution_path\":\"keyword_only\"}"}
{"type": "file", "path": "/Users/ciarancox/Archon/agents/context-bundles/20250911-200710-kickoff-context/artifacts/rag_success_criteria.json", "relpath": "agents/context-bundles/20250911-200710-kickoff-context/artifacts/rag_success_criteria.json", "size": 192, "sha256": "3eb45a7d16c932ac0b58515924d10485fbf113bf3798e7421d9043a3222ca213", "created_at": "2025-09-11T20:16:55.709898+00:00", "content": "{\"results\":[],\"query\":\"success criteria\",\"source\":null,\"match_count\":20,\"total_found\":0,\"execution_path\":\"rag_service_pipeline\",\"search_mode\":\"hybrid\",\"reranking_applied\":false,\"success\":true}"}
{"type": "file", "path": "/Users/ciarancox/Archon/agents/context-bundles/20250911-200710-kickoff-context/artifacts/rag_phase_b_delegate.json", "relpath": "agents/context-bundles/20250911-200710-kickoff-context/artifacts/rag_phase_b_delegate.json", "size": 211, "sha256": "bec001d51c98367fc1443dc88e73cb611b4fa201ae1822ae31574c02693e89cd", "created_at": "2025-09-11T20:16:55.740876+00:00", "content": "{\"results\":[],\"query\":\"Phase B — Delegate (Sub‑agents)\",\"source\":null,\"match_count\":20,\"total_found\":0,\"execution_path\":\"rag_service_pipeline\",\"search_mode\":\"hybrid\",\"reranking_applied\":false,\"success\":true}"}
{"type": "findings", "bullets": ["RAG baseline: 0 results for both queries with match_count=20 (mode=hybrid).", "Keyword baseline: 3 matches for \"success criteria\"; top file=PRP.md", "Keyword baseline: 2 matches for \"Phase B — Delegate\"; headers snippet=### Phase B — Delegate (Sub‑agents); ### Phase C — Advanced R&D (Bundles + Background); ## 7) Validation & QA Gates; ## ...", "Observation: vector/hybrid pipeline returned zero; keyword found PRP.md sections — consider lowering similarity threshold and/or verifying embeddings exist for local files."], "created_at": "2025-09-11T20:17:16.024755+00:00"}
{"type": "file", "path": "/Users/ciarancox/Archon/configs/mcp/firecrawl.json", "relpath": "configs/mcp/firecrawl.json", "size": 454, "sha256": "43082a31320a82176e8f280698dfe57dd9dacc821833358a94f9a69881f4a039", "created_at": "2025-09-11T20:28:08.243442+00:00", "content": "{\n  \"mcpServers\": {\n    \"firecrawl\": {\n      \"transport\": {\n        \"type\": \"http\",\n        \"url\": \"http://localhost:3001\"\n      },\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"${FIRECRAWL_API_KEY}\"\n      },\n      \"metadata\": {\n        \"description\": \"Firecrawl MCP server. Keep disabled by default; enable per-task only.\",\n        \"notes\": \"Set FIRECRAWL_API_KEY in your environment. If your Firecrawl MCP runs elsewhere, edit url.\"\n      }\n    }\n  }\n}\n"}
{"type": "findings", "bullets": ["Added configs/mcp/firecrawl.json for optional Firecrawl MCP client. Do not autoload; enable per-task only as per PRP."], "created_at": "2025-09-11T20:28:08.276669+00:00"}
{"type": "findings", "bullets": ["Context bundle workflow documented in README with make targets: bundle-new, bundle-read, bundle-findings, bundle-load."], "created_at": "2025-09-11T20:29:56.109927+00:00"}
